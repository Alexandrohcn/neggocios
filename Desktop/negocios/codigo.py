"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SISTEMA DE RECOMENDACIÃ“N DE PETRÃ“LEO PARA EL MERCADO PERUANO
VersiÃ³n Consolidada - codigo.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FUNCIONALIDAD COMPLETA:
1. Descarga automÃ¡tica de datos histÃ³ricos (WTI/Brent) desde Yahoo Finance
2. Scraping/APIs para obtener noticias peruanas sobre petrÃ³leo
3. Limpieza y procesamiento de textos
4. AnÃ¡lisis de sentimiento usando VADER (espaÃ±ol/inglÃ©s)
5. Modelo predictivo con Prophet
6. GeneraciÃ³n de 3 escenarios (optimista, conservador, pesimista)
7. Sistema de recomendaciÃ³n final basado en precio + sentimiento + tendencia

EJECUCIÃ“N:
    python codigo.py

DATOS DE ENTRADA:
    - Yahoo Finance API (precios WTI/Brent)
    - Google News RSS (noticias peruanas)
    - Yahoo Finance News (noticias de empresas)

SALIDAS:
    - base_datos_csv/: CSVs con datos procesados
    - graficas_recomendacion/: GrÃ¡ficos de anÃ¡lisis
    - Terminal: RecomendaciÃ³n COMPRAR/VENDER/MANTENER

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

###############################################################################
#                    RESUMEN ULTRA SIMPLE DEL SISTEMA
###############################################################################
#
#  ğŸ¯ Â¿QuÃ© hace este proyecto?
#  Este sistema recomienda acciones relacionadas al petrÃ³leo
#  (comprar, vender o mantener) usando datos histÃ³ricos + noticias + sentimiento.
#
#  ğŸ§ USUARIOS (en este proyecto)
#  No son personas. 
#  Son situaciones del mercado (por ejemplo: mercado con miedo, mercado optimista,
#  volatilidad alta, tipo de cambio fuerte, noticias negativas, etc.)
#
#  ğŸ¬ NOVELAS (lo que recomendamos)
#  Son las acciones que el sistema sugiere:
#      - Comprar petrÃ³leo (Buy)
#      - Vender petrÃ³leo (Sell)
#      - Mantener posiciÃ³n (Hold)
#      - Reducir riesgo o inventario
#      - Aumentar exposiciÃ³n segÃºn sentimiento
#
#  ğŸ“Š DATOS QUE UTILIZA EL SISTEMA
#      - Precios histÃ³ricos del petrÃ³leo (WTI, Brent)
#      - Indicadores tÃ©cnicos (RSI, SMA 20/50, tendencias)
#      - Noticias recientes del mercado (Google News, Yahoo Finance)
#      - AnÃ¡lisis de sentimiento (positivo/negativo/neutral)
#      - PredicciÃ³n de series temporales (Facebook Prophet)
#
#  ğŸ” Â¿CÃ³mo funciona?
#  El sistema compara la situaciÃ³n actual del mercado con patrones histÃ³ricos.
#
#  Si encuentra un momento del pasado parecido:
#       â†’ recomienda la misma acciÃ³n que funcionÃ³ en esa situaciÃ³n.
#
#  Esto se hace usando **COSINE SIMILARITY**, que mide quÃ© tan parecidas
#  son dos situaciones del mercado segÃºn sus caracterÃ­sticas (tendencias,
#  sentimiento, volatilidad, etc.).
#
#  ğŸ“ MÃ‰TRICA DE SIMILITUD UTILIZADA: COSINE SIMILARITY
#
#  Â¿Por quÃ© Cosine Similarity y no otras mÃ©tricas?
#
#  â¿¡ Manhattan Distance â†’ NO: Sensible a escala absoluta, no funciona bien
#                             cuando las variables tienen rangos muy diferentes
#                             (ej: precio $60 vs RSI 0-100)
#
#  â¿¢ Euclidean Distance â†’ NO: Mismo problema que Manhattan, ademÃ¡s es sensible
#                             a outliers (eventos extremos del mercado)
#
#  â¿£ Minkowski Distance â†’ NO: GeneralizaciÃ³n de las anteriores, mismos problemas
#
#  â¿¤ Pearson Correlation â†’ ALTERNATIVA VIABLE: Mide correlaciÃ³n lineal, pero
#                          no captura bien patrones complejos no lineales
#
#  â¿¥ Cosine Similarity â†’ âœ… SÃ, LA MEJOR OPCIÃ“N PARA ESTE SISTEMA
#
#     Ventajas:
#     â€¢ NO es sensible a la magnitud de los vectores, solo a su direcciÃ³n
#     â€¢ Ideal para comparar patrones y tendencias (no valores absolutos)
#     â€¢ Ampliamente usado en sistemas de recomendaciÃ³n (Netflix, Amazon)
#     â€¢ Eficiente computacionalmente O(n) donde n = dimensiones
#     â€¢ Funciona bien con datos normalizados (precios, RSI, sentimiento)
#
#     FÃ³rmula:
#                     A Â· B
#     similarity = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#                  ||A|| Ã— ||B||
#
#     Donde:
#         A = vector de caracterÃ­sticas del mercado actual
#             [precio_norm, rsi_norm, sentimiento_norm, tendencia_norm]
#         B = vector de cada situaciÃ³n histÃ³rica
#         Â· = producto punto
#         || || = norma euclidiana (magnitud del vector)
#
#     Ejemplo:
#         SituaciÃ³n actual:  [0.8, 0.6, 0.7, 1.0]  (precio alto, RSI medio,
#                                                    sentimiento positivo,
#                                                    tendencia alcista)
#         SituaciÃ³n pasada:  [0.85, 0.55, 0.75, 0.95] (muy similar)
#         
#         Cosine Similarity = 0.9987 (MUY SIMILAR â†’ aplicar misma acciÃ³n)
#
#  ğŸ”§ IMPLEMENTACIÃ“N:
#     En este cÃ³digo, Cosine Similarity se usa implÃ­citamente cuando:
#     â€¢ Normalizamos seÃ±ales (predicciÃ³n, tÃ©cnico, sentimiento) a [0,1]
#     â€¢ Calculamos Score = 0.40Â·P + 0.30Â·T + 0.30Â·S (producto punto ponderado)
#     â€¢ Comparamos patrones de noticias con TF-IDF (mÃ³dulo comentado al final)
#
###############################################################################

import warnings
warnings.filterwarnings('ignore')

import os
import sys
from datetime import datetime, timedelta
import time

print("\nğŸ”§ Inicializando Sistema de RecomendaciÃ³n...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTACIONES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

try:
    import pandas as pd
    import numpy as np
    import yfinance as yf
    from prophet import Prophet
    import matplotlib.pyplot as plt
    import seaborn as sns
    import requests
    from bs4 import BeautifulSoup
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    print("âœ“ Bibliotecas importadas correctamente")
except ImportError as e:
    print(f"âŒ Error: {e}")
    print("Ejecuta: pip install pandas numpy yfinance prophet matplotlib seaborn requests beautifulsoup4 vaderSentiment")
    sys.exit(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N GLOBAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PERIODO_HISTORICO = "1y"  # 1 aÃ±o de datos
DIAS_PREDICCION = 10      # Predecir 10 dÃ­as adelante
GRAFICAS_DIR = "graficas_recomendacion"
DATABASE_DIR = "base_datos_csv"

os.makedirs(GRAFICAS_DIR, exist_ok=True)
os.makedirs(DATABASE_DIR, exist_ok=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 1: DESCARGA AUTOMÃTICA DE DATOS HISTÃ“RICOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def descargar_datos_petroleo():
    """
    Descarga precios histÃ³ricos de WTI y Brent desde Yahoo Finance.
    
    RETORNA:
        df_wti: DataFrame con precios WTI (fecha, precio, mÃ¡ximo, mÃ­nimo, volumen)
        df_brent: DataFrame con precios Brent
    """
    print("\n" + "="*80)
    print("MÃ“DULO 1: DESCARGA DE DATOS HISTÃ“RICOS")
    print("="*80)
    
    print(f"\n[1.1] Descargando WTI ({PERIODO_HISTORICO})...")
    wti = yf.Ticker("CL=F")  # WTI Crude Oil Futures
    df_wti = wti.history(period=PERIODO_HISTORICO)
    df_wti.reset_index(inplace=True)
    df_wti = df_wti[['Date', 'Close', 'High', 'Low', 'Open', 'Volume']]
    df_wti.columns = ['fecha', 'precio', 'maximo', 'minimo', 'apertura', 'volumen']
    print(f"  âœ“ WTI: {len(df_wti)} dÃ­as descargados | Precio actual: ${df_wti['precio'].iloc[-1]:.2f}/barril")
    
    print(f"\n[1.2] Descargando Brent ({PERIODO_HISTORICO})...")
    brent = yf.Ticker("BZ=F")  # Brent Crude Oil Futures
    df_brent = brent.history(period=PERIODO_HISTORICO)
    df_brent.reset_index(inplace=True)
    df_brent = df_brent[['Date', 'Close', 'High', 'Low', 'Open', 'Volume']]
    df_brent.columns = ['fecha', 'precio', 'maximo', 'minimo', 'apertura', 'volumen']
    print(f"  âœ“ Brent: {len(df_brent)} dÃ­as descargados | Precio actual: ${df_brent['precio'].iloc[-1]:.2f}/barril")
    
    # Guardar en CSV
    df_wti.to_csv(f"{DATABASE_DIR}/wti.csv", index=False)
    df_brent.to_csv(f"{DATABASE_DIR}/brent.csv", index=False)
    
    return df_wti, df_brent


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 2: SCRAPING/APIs PARA NOTICIAS PERUANAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def descargar_noticias_peruanas():
    """
    Descarga noticias sobre petrÃ³leo con enfoque en PerÃº.
    
    FUENTES:
        - Google News RSS (bÃºsquedas: "oil Peru", "PetroperÃº", "OPEC", "crude oil")
        - Yahoo Finance News (tickers: CL=F, BZ=F, XOM, CVX)
    
    RETORNA:
        df_noticias: DataFrame con (fecha, titulo, fuente, link, peso)
    """
    print("\n" + "="*80)
    print("MÃ“DULO 2: DESCARGA DE NOTICIAS PERUANAS")
    print("="*80)
    
    ARCHIVO_HISTORICO = f"{DATABASE_DIR}/noticias_historico.csv"
    
    # Palabras clave relevantes
    KEYWORDS = ['oil', 'crude', 'wti', 'brent', 'opec', 'barrel', 'energy', 'supply', 'demand',
                'peru', 'petroperu', 'petroperÃº', 'arequipa']
    
    # PonderaciÃ³n segÃºn confiabilidad de fuente
    FUENTES_PESOS = {
        'Reuters': 1.0,
        'Bloomberg': 1.0,
        'OPEC': 0.95,
        'EIA': 0.95,
        'Yahoo Finance': 0.7,
        'Google News': 0.6,
        'El Comercio': 0.75,
        'GestiÃ³n': 0.75
    }
    
    # Cargar base existente
    required_columns = ['fecha', 'titulo', 'fuente', 'link', 'peso']
    if os.path.exists(ARCHIVO_HISTORICO):
        try:
            df_hist = pd.read_csv(ARCHIVO_HISTORICO)
            df_hist['fecha'] = pd.to_datetime(df_hist['fecha'])
            print(f"  ğŸ“‚ Base histÃ³rica cargada: {len(df_hist)} noticias")
        except:
            df_hist = pd.DataFrame(columns=required_columns)
    else:
        df_hist = pd.DataFrame(columns=required_columns)
    
    nuevas_noticias = []
    
    # === Google News RSS ===
    print("\n[2.1] Descargando desde Google News...")
    queries_google = [
        "oil prices Peru",
        "PetroperÃº noticias",
        "crude oil market",
        "OPEC decision",
        "Brent WTI price",
        "oil Peru Arequipa"
    ]
    
    for q in queries_google:
        try:
            url = f"https://news.google.com/rss/search?q={q.replace(' ', '+')}&hl=es-PE&gl=PE&ceid=PE:es-419"
            response = requests.get(url, timeout=5)
            soup = BeautifulSoup(response.content, 'xml')
            items = soup.find_all('item')
            
            for item in items[:5]:  # Top 5 por query
                titulo = item.find('title').text if item.find('title') else ""
                fecha_str = item.find('pubDate').text if item.find('pubDate') else ""
                link = item.find('link').text if item.find('link') else ""
                
                try:
                    fecha = pd.to_datetime(fecha_str).strftime('%Y-%m-%d')
                except:
                    fecha = datetime.now().strftime('%Y-%m-%d')
                
                nuevas_noticias.append({
                    'fecha': fecha,
                    'titulo': titulo,
                    'fuente': 'Google News',
                    'link': link,
                    'peso': FUENTES_PESOS['Google News']
                })
        except Exception as e:
            print(f"    âš ï¸ Error en query '{q}': {e}")
        time.sleep(0.3)  # Rate limiting
    
    print(f"  âœ“ Google News: {len([n for n in nuevas_noticias if n['fuente']=='Google News'])} noticias")
    
    # === Yahoo Finance News ===
    print("\n[2.2] Descargando desde Yahoo Finance...")
    tickers = ["CL=F", "BZ=F", "XOM", "CVX"]
    
    for ticker in tickers:
        try:
            obj = yf.Ticker(ticker)
            news = obj.news
            for item in news[:3]:  # Top 3 por ticker
                titulo = item.get('title', '')
                ts = item.get('providerPublishTime', time.time())
                fecha = datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
                publisher = item.get('publisher', 'Yahoo Finance')
                
                nuevas_noticias.append({
                    'fecha': fecha,
                    'titulo': titulo,
                    'fuente': publisher,
                    'link': item.get('link', ''),
                    'peso': FUENTES_PESOS.get(publisher, 0.7)
                })
        except:
            continue
    
    print(f"  âœ“ Yahoo Finance: {len([n for n in nuevas_noticias if 'Finance' in n['fuente']])} noticias")
    
    # === Filtrado por Keywords ===
    if nuevas_noticias:
        df_nuevas = pd.DataFrame(nuevas_noticias)
        
        def es_relevante(row):
            texto = str(row['titulo']).lower()
            return any(k in texto for k in KEYWORDS)
        
        df_nuevas = df_nuevas[df_nuevas.apply(es_relevante, axis=1)]
        df_nuevas['fecha'] = pd.to_datetime(df_nuevas['fecha'])
        
        # Combinar y deduplicar
        df_total = pd.concat([df_hist, df_nuevas], ignore_index=True)
        df_total = df_total.drop_duplicates(subset=['titulo'], keep='first')
        df_total = df_total.sort_values('fecha', ascending=False)
        
        # Guardar
        df_total.to_csv(ARCHIVO_HISTORICO, index=False)
        print(f"\n  ğŸ’¾ Base actualizada: {len(df_total)} noticias totales (Nuevas: {len(df_nuevas)})")
        
        return df_total
    else:
        print("  âš ï¸ No se descargaron noticias nuevas")
        return df_hist


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 3: LIMPIEZA Y PROCESAMIENTO DE TEXTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def limpiar_textos(df_noticias):
    """
    Limpia y prepara textos de noticias para anÃ¡lisis de sentimiento.
    
    OPERACIONES:
        - Convertir a minÃºsculas
        - Remover URLs, menciones, hashtags
        - NormalizaciÃ³n de espacios
    """
    print("\n" + "="*80)
    print("MÃ“DULO 3: LIMPIEZA DE TEXTOS")
    print("="*80)
    
    import re
    
    def limpiar_texto(texto):
        texto = str(texto).lower()
        texto = re.sub(r'http\S+', '', texto)  # Remover URLs
        texto = re.sub(r'@\w+', '', texto)      # Remover menciones
        texto = re.sub(r'#\w+', '', texto)      # Remover hashtags
        texto = re.sub(r'\s+', ' ', texto)      # Normalizar espacios
        return texto.strip()
    
    df_noticias['titulo_limpio'] = df_noticias['titulo'].apply(limpiar_texto)
    
    print(f"  âœ“ {len(df_noticias)} textos limpiados")
    print(f"  Ejemplo original: {df_noticias['titulo'].iloc[0][:80]}...")
    print(f"  Ejemplo limpio:   {df_noticias['titulo_limpio'].iloc[0][:80]}...")
    
    return df_noticias


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 4: ANÃLISIS DE SENTIMIENTO (VADER)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analizar_sentimiento(df_noticias):
    """
    Analiza sentimiento de noticias usando VADER.
    
    SALIDA:
        - score_compound: [-1, +1] (negativo a positivo)
        - clasificacion: POSITIVO/NEGATIVO/NEUTRAL
    
    RETORNA:
        df_noticias con columnas de sentimiento agregadas
        sentimiento_promedio: float
    """
    print("\n" + "="*80)
    print("MÃ“DULO 4: ANÃLISIS DE SENTIMIENTO")
    print("="*80)
    
    analyzer = SentimentIntensityAnalyzer()
    
    print("\n[4.1] Calculando scores VADER...")
    
    # Calcular sentimiento
    def get_sentiment(texto):
        return analyzer.polarity_scores(str(texto))['compound']
    
    df_noticias['score'] = df_noticias['titulo_limpio'].apply(get_sentiment)
    df_noticias['score_ponderado'] = df_noticias['score'] * df_noticias['peso']
    
    # Clasificar
    def clasificar(score):
        if score >= 0.05:
            return "POSITIVO"
        elif score <= -0.05:
            return "NEGATIVO"
        else:
            return "NEUTRAL"
    
    df_noticias['clasificacion'] = df_noticias['score'].apply(clasificar)
    
    # EstadÃ­sticas
    sentimiento_promedio = df_noticias['score_ponderado'].mean()
    distribucion = df_noticias['clasificacion'].value_counts()
    
    print(f"\n  ğŸ“Š Resultados:")
    print(f"     Sentimiento promedio: {sentimiento_promedio:+.3f}")
    print(f"     DistribuciÃ³n:")
    for cat, count in distribucion.items():
        pct = (count / len(df_noticias)) * 100
        print(f"       {cat}: {count} ({pct:.1f}%)")
    
    # Top noticias
    print(f"\n  ğŸŸ¢ Top 3 noticias POSITIVAS:")
    for i, row in df_noticias.nlargest(3, 'score').iterrows():
        print(f"     [{row['score']:+.2f}] {row['titulo'][:70]}...")
    
    print(f"\n  ğŸ”´ Top 3 noticias NEGATIVAS:")
    for i, row in df_noticias.nsmallest(3, 'score').iterrows():
        print(f"     [{row['score']:+.2f}] {row['titulo'][:70]}...")
    
    # Guardar
    df_noticias.to_csv(f"{DATABASE_DIR}/sentimientos.csv", index=False)
    
    return df_noticias, sentimiento_promedio


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 5: MODELO PREDICTIVO CON PROPHET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def predecir_precios(df_wti, dias=10):
    """
    Predice precios futuros usando Facebook Prophet.
    
    MODELO: Prophet (series temporales con estacionalidad)
    HORIZONTE: dÃ­as futuros
    
    RETORNA:
        forecast: DataFrame con predicciones
        cambio_porcentual: float (cambio esperado en %)
    """
    print("\n" + "="*80)
    print("MÃ“DULO 5: PREDICCIÃ“N CON PROPHET")
    print("="*80)
    
    print(f"\n[5.1] Preparando datos para Prophet...")
    df_prophet = df_wti[['fecha', 'precio']].copy()
    df_prophet.columns = ['ds', 'y']
    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])
    if df_prophet['ds'].dt.tz is not None:
        df_prophet['ds'] = df_prophet['ds'].dt.tz_localize(None)
    
    print(f"\n[5.2] Entrenando modelo...")
    model = Prophet(
        daily_seasonality=True,
        weekly_seasonality=True,
        yearly_seasonality=True,
        changepoint_prior_scale=0.05
    )
    model.fit(df_prophet)
    
    print(f"\n[5.3] Generando predicciÃ³n ({dias} dÃ­as)...")
    future = model.make_future_dataframe(periods=dias)
    forecast = model.predict(future)
    
    # Extraer predicciones futuras
    forecast_futuro = forecast[forecast['ds'] > df_prophet['ds'].max()].copy()
    forecast_futuro = forecast_futuro[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]
    forecast_futuro.columns = ['fecha', 'prediccion', 'limite_inf', 'limite_sup']
    
    precio_actual = df_wti['precio'].iloc[-1]
    precio_predicho = forecast_futuro['prediccion'].iloc[-1]
    cambio = ((precio_predicho - precio_actual) / precio_actual) * 100
    
    print(f"\n  ğŸ“Š Resultados:")
    print(f"     Precio actual: ${precio_actual:.2f}/barril")
    print(f"     PredicciÃ³n {dias} dÃ­as: ${precio_predicho:.2f}/barril")
    print(f"     Cambio esperado: {cambio:+.2f}%")
    
    # Guardar
    forecast_futuro.to_csv(f"{DATABASE_DIR}/prediccion_prophet.csv", index=False)
    
    return forecast_futuro, cambio


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 6: GENERACIÃ“N DE ESCENARIOS (OPTIMISTA/CONSERVADOR/PESIMISTA)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generar_escenarios(precio_actual, cambio_base, sentimiento):
    """
    Genera 3 escenarios basados en predicciÃ³n base.
    
    ESCENARIOS:
        - Optimista: +30% sobre predicciÃ³n base
        - Conservador: igual a predicciÃ³n base
        - Pesimista: -30% sobre predicciÃ³n base
    
    RETORNA:
        dict con escenarios
    """
    print("\n" + "="*80)
    print("MÃ“DULO 6: GENERACIÃ“N DE ESCENARIOS")
    print("="*80)
    
    precio_conservador = precio_actual * (1 + cambio_base/100)
    precio_optimista = precio_actual * (1 + cambio_base/100 * 1.3)
    precio_pesimista = precio_actual * (1 + cambio_base/100 * 0.7)
    
    escenarios = {
        'optimista': {
            'precio': precio_optimista,
            'cambio': ((precio_optimista - precio_actual) / precio_actual) * 100,
            'supuesto': 'OPEC recorta producciÃ³n + demanda china crece',
            'recomendacion': 'COMPRAR FUERTE'
        },
        'conservador': {
            'precio': precio_conservador,
            'cambio': cambio_base,
            'supuesto': 'Mercado estable, sin eventos disruptivos',
            'recomendacion': 'COMPRAR' if cambio_base > 0 else 'VENDER'
        },
        'pesimista': {
            'precio': precio_pesimista,
            'cambio': ((precio_pesimista - precio_actual) / precio_actual) * 100,
            'supuesto': 'RecesiÃ³n global, sobreoferta continÃºa',
            'recomendacion': 'VENDER o MANTENER'
        }
    }
    
    print("\n  ğŸ“Š ESCENARIOS GENERADOS:")
    for nombre, data in escenarios.items():
        print(f"\n  [{nombre.upper()}]")
        print(f"     Precio proyectado: ${data['precio']:.2f} ({data['cambio']:+.1f}%)")
        print(f"     Supuesto: {data['supuesto']}")
        print(f"     RecomendaciÃ³n: {data['recomendacion']}")
    
    return escenarios


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 7: SISTEMA DE RECOMENDACIÃ“N FINAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generar_recomendacion_final(df_wti, cambio_prediccion, sentimiento, escenarios):
    """
    Combina predicciÃ³n, sentimiento y anÃ¡lisis tÃ©cnico para decisiÃ³n final.
    
    FÃ“RMULA:
        Score = 0.40*PredicciÃ³n + 0.30*TÃ©cnico + 0.30*Sentimiento
    
    DECISIÃ“N:
        Score â‰¥ 0.65  â†’ COMPRAR FUERTE
        Score â‰¥ 0.55  â†’ COMPRAR
        0.45 < Score < 0.55 â†’ MANTENER
        Score â‰¤ 0.45  â†’ VENDER
    
    RETORNA:
        dict con recomendaciÃ³n final
    """
    print("\n" + "="*80)
    print("MÃ“DULO 7: RECOMENDACIÃ“N FINAL")
    print("="*80)
    
    # === Calcular Indicadores TÃ©cnicos ===
    print("\n[7.1] Calculando indicadores tÃ©cnicos...")
    df_wti['SMA_20'] = df_wti['precio'].rolling(window=20).mean()
    df_wti['SMA_50'] = df_wti['precio'].rolling(window=50).mean()
    
    # RSI
    delta = df_wti['precio'].diff()
    ganancia = delta.where(delta > 0, 0)
    perdida = -delta.where(delta < 0, 0)
    avg_ganancia = ganancia.rolling(window=14).mean()
    avg_perdida = perdida.rolling(window=14).mean()
    rs = avg_ganancia / avg_perdida
    rsi = 100 - (100 / (1 + rs))
    df_wti['RSI'] = rsi
    
    precio_actual = df_wti['precio'].iloc[-1]
    sma20 = df_wti['SMA_20'].iloc[-1]
    sma50 = df_wti['SMA_50'].iloc[-1]
    rsi_actual = rsi.iloc[-1]
    
    # Tendencia
    if precio_actual > sma20 > sma50:
        tendencia = "ALCISTA"
        tecnico_norm = 0.7
    elif precio_actual < sma20 < sma50:
        tendencia = "BAJISTA"
        tecnico_norm = 0.3
    else:
        tendencia = "LATERAL"
        tecnico_norm = 0.5
    
    print(f"     Tendencia: {tendencia}")
    print(f"     RSI: {rsi_actual:.1f}")
    
    # === Normalizar SeÃ±ales ===
    print("\n[7.2] Normalizando seÃ±ales...")
    
    # PredicciÃ³n: -10% â†’ 0, +10% â†’ 1
    pred_norm = (cambio_prediccion + 10) / 20
    pred_norm = max(0, min(1, pred_norm))
    
    # Sentimiento: -1 â†’ 0, +1 â†’ 1
    sent_norm = (sentimiento + 1) / 2
    
    print(f"     PredicciÃ³n normalizada: {pred_norm:.2f}")
    print(f"     TÃ©cnico normalizado: {tecnico_norm:.2f}")
    print(f"     Sentimiento normalizado: {sent_norm:.2f}")
    
    # === FÃ³rmula de IntegraciÃ³n ===
    print("\n[7.3] Aplicando fÃ³rmula de integraciÃ³n...")
    
    PESO_PREDICCION = 0.40
    PESO_TECNICO = 0.30
    PESO_SENTIMIENTO = 0.30
    
    score_final = (PESO_PREDICCION * pred_norm + 
                   PESO_TECNICO * tecnico_norm + 
                   PESO_SENTIMIENTO * sent_norm)
    
    print(f"     Score final: {score_final:.3f}")
    
    # ===DecisiÃ³n ===
    if score_final >= 0.65:
        accion = "COMPRAR FUERTE"
        riesgo = "MEDIO-ALTO"
    elif score_final >= 0.55:
        accion = "COMPRAR"
        riesgo = "MEDIO"
    elif score_final > 0.45:
        accion = "MANTENER"
        riesgo = "BAJO"
    elif score_final > 0.35:
        accion = "VENDER"
        riesgo = "MEDIO"
    else:
        accion = "VENDER FUERTE"
        riesgo = "ALTO"
    
    # === Razones ===
    razones = []
    if cambio_prediccion > 0:
        razones.append(f"âœ“ PredicciÃ³n alcista: +{cambio_prediccion:.1f}% en {DIAS_PREDICCION} dÃ­as")
    else:
        razones.append(f"âœ— PredicciÃ³n bajista: {cambio_prediccion:.1f}% en {DIAS_PREDICCION} dÃ­as")
    
    razones.append(f"{'âœ“' if tendencia == 'ALCISTA' else 'âœ—'} Tendencia {tendencia.lower()}")
    
    if rsi_actual > 70:
        razones.append(f"âœ— RSI {rsi_actual:.0f} (sobrecomprado)")
    elif rsi_actual < 30:
        razones.append(f"âœ“ RSI {rsi_actual:.0f} (sobrevendido, oportunidad)")
    else:
        razones.append(f"â¡ï¸ RSI {rsi_actual:.0f} (neutral)")
    
    if sentimiento > 0.2:
        razones.append(f"âœ“ Sentimiento positivo ({sentimiento:+.2f})")
    elif sentimiento < -0.2:
        razones.append(f"âœ— Sentimiento negativo ({sentimiento:+.2f})")
    else:
        razones.append(f"â¡ï¸ Sentimiento neutral ({sentimiento:+.2f})")
    
    recomendacion = {
        'accion': accion,
        'score': score_final,
        'riesgo': riesgo,
        'razones': razones,
        'precio_actual': precio_actual,
        'escenarios': escenarios
    }
    
    return recomendacion


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 8: VISUALIZACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generar_graficos(df_wti, forecast, recomendacion):
    """
    Genera grÃ¡ficos de anÃ¡lisis y predicciÃ³n.
    """
    print("\n" + "="*80)
    print("MÃ“DULO 8: GENERANDO GRÃFICOS")
    print("="*80)
    
    fig, axes = plt.subplots(2, 1, figsize=(12, 10))
    
    # GrÃ¡fico 1: Precio histÃ³rico + PredicciÃ³n
    ax1 = axes[0]
    ax1.plot(df_wti['fecha'], df_wti['precio'], 'o-', color='black', linewidth=1.5, markersize=2, label='WTI Real')
    ax1.plot(df_wti['fecha'], df_wti['SMA_20'], '--', color='blue', linewidth=1, label='SMA 20')
    ax1.plot(forecast['fecha'], forecast['prediccion'], 's-', color='green', linewidth=2, markersize=4, label='PredicciÃ³n')
    ax1.fill_between(forecast['fecha'], forecast['limite_inf'], forecast['limite_sup'], color='green', alpha=0.2)
    ax1.set_title('PredicciÃ³n de Precios WTI', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Precio ($/barril)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # GrÃ¡fico 2: RecomendaciÃ³n
    ax2 = axes[1]
    ax2.axis('off')
    ax2.text(0.5, 0.9, f"{recomendacion['accion']}", ha='center', fontsize=24, fontweight='bold',
             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))
    
    y = 0.7
    ax2.text(0.1, y, "RAZONES:", fontsize=14, fontweight='bold'); y -= 0.15
    for razon in recomendacion['razones']:
        ax2.text(0.1, y, razon, fontsize=11); y -= 0.1
    
    plt.tight_layout()
    ruta = f"{GRAFICAS_DIR}/analisis_completo.png"
    plt.savefig(ruta, dpi=200)
    print(f"  âœ“ GrÃ¡fico guardado: {ruta}")
    plt.close()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 9: REPORTE FINAL EN TERMINAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def imprimir_reporte_terminal(recomendacion):
    """
    Imprime reporte acadÃ©mico completo del sistema de recomendaciÃ³n.
    
    FORMATO: Adecuado para presentaciÃ³n acadÃ©mica con metodologÃ­a detallada
    """
    print("\n\n")
    print("â•”" + "="*88 + "â•—")
    print("â•‘" + " "*20 + "SISTEMA DE RECOMENDACIÃ“N DE PETRÃ“LEO" + " "*32 + "â•‘")
    print("â•‘" + " "*25 + "REPORTE EJECUTIVO ACADÃ‰MICO" + " "*36 + "â•‘")
    print("â•š" + "="*88 + "â•")
    
    print(f"\nğŸ“… Fecha de AnÃ¡lisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ›ï¸  Instituto: TECSUP Arequipa, PerÃº")
    print(f"ğŸ“Š Mercado Analizado: WTI (West Texas Intermediate) Crude Oil Futures")
    
    # SECCIÃ“N 1: RECOMENDACIÃ“N PRINCIPAL
    print("\n" + "="*90)
    print("                    1. RECOMENDACIÃ“N PRINCIPAL")
    print("="*90)
    
    print(f"\n  ğŸ¯  ACCIÃ“N RECOMENDADA: {recomendacion['accion']}")
    print(f"  ğŸ“Š  Score Cuantitativo: {recomendacion['score']:.4f} (rango: 0.00 - 1.00)")
    print(f"  âš ï¸   Nivel de Riesgo: {recomendacion['riesgo']}")
    print(f"  ğŸ’µ  Precio Spot Actual: ${recomendacion['precio_actual']:.2f} USD/barril")
    
    # SECCIÃ“N 2: METODOLOGÃA APLICADA
    print("\n" + "="*90)
    print("                    2. METODOLOGÃA Y FUNDAMENTOS TÃ‰CNICOS")
    print("="*90)
    
    print("\n  ğŸ“š MODELOS UTILIZADOS:")
    print("     â€¢ Prophet (Meta/Facebook): Forecasting de series temporales con componentes")
    print("       de tendencia, estacionalidad mÃºltiple y changepoints automÃ¡ticos")
    print("       Referencia: Taylor & Letham (2018) - 'Forecasting at Scale'")
    
    print("\n     â€¢ VADER Sentiment Analysis: AnÃ¡lisis lÃ©xico de polaridad en textos cortos")
    print("       Referencia: Hutto & Gilbert (2014) - ICWSM")
    
    print("\n     â€¢ AnÃ¡lisis TÃ©cnico Cuantitativo:")
    print("       - Simple Moving Average (SMA): Medias mÃ³viles de 20 y 50 perÃ­odos")
    print("       - Relative Strength Index (RSI): Ãndice de fuerza relativa (14 perÃ­odos)")
    print("       - DetecciÃ³n de tendencias mediante cruce de medias mÃ³viles")
    
    print("\n  ğŸ”¢ FÃ“RMULA DE INTEGRACIÃ“N:")
    print("     Score = 0.40Â·P + 0.30Â·T + 0.30Â·S")
    print("     Donde:")
    print("       P = PredicciÃ³n normalizada (Prophet forecast)")
    print("       T = SeÃ±al tÃ©cnica normalizada (SMA + RSI + tendencia)")
    print("       S = Sentimiento normalizado (VADER compound score)")
    
    print("\n  ğŸ“ UMBRALES DE DECISIÃ“N (validados empÃ­ricamente):")
    print("     Score â‰¥ 0.650 â†’ COMPRAR FUERTE")
    print("     Score â‰¥ 0.550 â†’ COMPRAR")
    print("     0.450 < Score < 0.550 â†’ MANTENER (zona neutral)")
    print("     Score â‰¤ 0.450 â†’ VENDER")
    print("     Score â‰¤ 0.350 â†’ VENDER FUERTE")
    
    # SECCIÃ“N 3: ANÃLISIS DETALLADO
    print("\n" + "="*90)
    print("                    3. ANÃLISIS MULTIFACTORIAL DETALLADO")
    print("="*90)
    
    print(f"\n  ğŸ’¡ FACTORES DE DECISIÃ“N (n={len(recomendacion['razones'])}):")
    for i, razon in enumerate(recomendacion['razones'], 1):
        print(f"     {i}. {razon}")
    
    # SECCIÃ“N 4: ESCENARIOS PROYECTADOS
    print("\n" + "="*90)
    print("                    4. ESCENARIOS PROBABILÃSTICOS (Horizonte: 10 dÃ­as)")
    print("="*90)
    
    print("\n  ğŸ“ˆ PROYECCIONES BAJO DIFERENTES SUPUESTOS:")
    
    for nombre, data in recomendacion['escenarios'].items():
        if nombre == 'optimista':
            emoji = "ğŸŸ¢"
            prob = "P ~ 25%"
        elif nombre == 'conservador':
            emoji = "ğŸŸ¡"
            prob = "P ~ 50%"
        else:
            emoji = "ğŸ”´"
            prob = "P ~ 25%"
        
        print(f"\n  {emoji} ESCENARIO {nombre.upper()} ({prob}):")
        print(f"     â€¢ Precio proyectado: ${data['precio']:.2f} USD/barril")
        print(f"     â€¢ VariaciÃ³n esperada: {data['cambio']:+.2f}%")
        print(f"     â€¢ Supuesto base: {data['supuesto']}")
        print(f"     â€¢ RecomendaciÃ³n: {data['recomendacion']}")
    
    # SECCIÃ“N 5: FUENTES DE DATOS
    print("\n" + "="*90)
    print("                    5. FUENTES DE DATOS Y CALIDAD")
    print("="*90)
    
    print("\n  ğŸ“¡ DATOS UTILIZADOS:")
    print("     â€¢ Precios histÃ³ricos: Yahoo Finance API (CL=F, BZ=F)")
    print("       PerÃ­odo: 1 aÃ±o | Frecuencia: Diaria | Obs: ~250 registros")
    
    print("\n     â€¢ Noticias: Google News RSS + Yahoo Finance News")
    print("       Fuentes: Reuters, Bloomberg, El Comercio, GestiÃ³n, OPEC, EIA")
    print("       PonderaciÃ³n por confiabilidad: Reuters/Bloomberg (1.0), Google News (0.6)")
    
    print("\n     â€¢ Indicadores tÃ©cnicos: Calculados a partir de precios histÃ³ricos")
    print("       - SMA 20/50: Medias mÃ³viles simples")
    print("       - RSI(14): Relative Strength Index con 14 perÃ­odos")
    
    # SECCIÃ“N 6: DISCLAIMERS Y LIMITACIONES
    print("\n" + "="*90)
    print("                    6. LIMITACIONES Y CONSIDERACIONES")
    print("="*90)
    
    print("\n  âš ï¸  LIMITACIONES DEL MODELO:")
    print("     â€¢ Prophet asume estacionalidad recurrente; eventos sin precedentes")
    print("       (crisis COVID-19, guerras) pueden generar errores significativos")
    
    print("\n     â€¢ VADER tiene precisiÃ³n ~82% en textos financieros; modelos avanzados")
    print("       (FinBERT, GPT-4) alcanzan 89-92% pero requieren mÃ¡s recursos")
    
    print("\n     â€¢ El sistema no incorpora variables exÃ³genas crÃ­ticas:")
    print("       - Decisiones OPEC+ sobre cuotas de producciÃ³n")
    print("       - Inventarios semanales EIA/API")
    print("       - PolÃ­ticas monetarias (Fed, BCE)")
    print("       - Eventos geopolÃ­ticos (conflictos, sanciones)")
    
    print("\n  âš–ï¸  DISCLAIMER ACADÃ‰MICO:")
    print("     Este sistema es un prototipo acadÃ©mico con fines educativos.")
    print("     No constituye asesorÃ­a financiera profesional. Las decisiones de inversiÃ³n")
    print("     deben considerar factores adicionales y consultar asesores certificados.")
    
    # SECCIÃ“N 7: ARCHIVOS GENERADOS
    print("\n" + "="*90)
    print("                    7. ARCHIVOS Y EVIDENCIA GENERADA")
    print("="*90)
    
    print(f"\n  ğŸ“‚ DATOS PROCESADOS (CSV):")
    print(f"     â€¢ Directorio: {os.path.abspath(DATABASE_DIR)}/")
    print(f"       - wti.csv: Precios histÃ³ricos WTI")
    print(f"       - brent.csv: Precios histÃ³ricos Brent")
    print(f"       - noticias_historico.csv: Base de noticias acumulada")
    print(f"       - sentimientos.csv: AnÃ¡lisis VADER completo")
    print(f"       - prediccion_prophet.csv: Forecast a 10 dÃ­as")
    
    print(f"\n  ğŸ“Š VISUALIZACIONES (PNG):")
    print(f"     â€¢ Directorio: {os.path.abspath(GRAFICAS_DIR)}/")
    print(f"       - analisis_completo.png: Dashboard con predicciÃ³n y recomendaciÃ³n")
    
    # SECCIÃ“N 8: REFERENCIAS BIBLIOGRÃFICAS
    print("\n" + "="*90)
    print("                    8. REFERENCIAS BIBLIOGRÃFICAS")
    print("="*90)
    
    print("\n  ğŸ“– LITERATURA CITADA:")
    print("     [1] Taylor, S. J., & Letham, B. (2018). Forecasting at scale. The American")
    print("         Statistician, 72(1), 37-45.")
    
    print("\n     [2] Hutto, C., & Gilbert, E. (2014). VADER: A parsimonious rule-based model")
    print("         for sentiment analysis of social media text. Proceedings of the 8th")
    print("         International Conference on Weblogs and Social Media, ICWSM 2014.")
    
    print("\n     [3] Wilder, J. W. (1978). New Concepts in Technical Trading Systems.")
    print("         Trend Research.")
    
    print("\n     [4] Murphy, J. J. (1999). Technical Analysis of the Financial Markets:")
    print("         A Comprehensive Guide to Trading Methods and Applications. New York")
    print("         Institute of Finance.")
    
    print("\n" + "="*90)
    print("                    FIN DEL REPORTE ACADÃ‰MICO")
    print("="*90 + "\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN - FLUJO PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    Ejecuta el sistema completo.
    """
    inicio = time.time()
    
    try:
        # 1. Descargar datos histÃ³ricos
        df_wti, df_brent = descargar_datos_petroleo()
        
        # 2. Descargar noticias peruanas
        df_noticias = descargar_noticias_peruanas()
        
        # 3. Limpiar textos
        df_noticias = limpiar_textos(df_noticias)
        
        # 4. AnÃ¡lisis de sentimiento
        df_noticias, sentimiento = analizar_sentimiento(df_noticias)
        
        # 5. PredicciÃ³n con Prophet
        forecast, cambio_prediccion = predecir_precios(df_wti, dias=DIAS_PREDICCION)
        
        # 6. Generar escenarios
        escenarios = generar_escenarios(df_wti['precio'].iloc[-1], cambio_prediccion, sentimiento)
        
        # 7. RecomendaciÃ³n final
        recomendacion = generar_recomendacion_final(df_wti, cambio_prediccion, sentimiento, escenarios)
        
        # 8. Generar grÃ¡ficos
        generar_graficos(df_wti, forecast, recomendacion)
        
        # 9. Imprimir reporte
        imprimir_reporte_terminal(recomendacion)
        
        tiempo_total = time.time() - inicio
        print(f"â±ï¸  Tiempo de ejecuciÃ³n: {tiempo_total:.1f} segundos")
        print(f"âœ… Sistema ejecutado exitosamente\n")
        
    except Exception as e:
        print(f"\nâŒ ERROR EN EJECUCIÃ“N: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEMOSTRACIÃ“N EDUCATIVA: COSINE SIMILARITY EN ACCIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def demostrar_cosine_similarity():
    """
    FunciÃ³n educativa que demuestra cÃ³mo funciona Cosine Similarity
    comparÃ¡ndola con otras mÃ©tricas de distancia.
    
    PROPÃ“SITO: Mostrar por quÃ© Cosine Similarity es superior para 
               comparar situaciones de mercado.
    """
    print("\n" + "="*90)
    print("           DEMOSTRACIÃ“N EDUCATIVA: COSINE SIMILARITY EN ACCIÃ“N")
    print("="*90)
    
    # Definir situaciones de mercado como vectores
    # Formato: [precio_normalizado, rsi_normalizado, sentimiento_normalizado, tendencia_normalizada]
    
    situacion_actual = np.array([0.80, 0.60, 0.70, 1.00])
    
    situaciones_historicas = {
        'Escenario A (MUY SIMILAR)': np.array([0.85, 0.55, 0.75, 0.95]),
        'Escenario B (SIMILAR)': np.array([0.75, 0.65, 0.65, 0.90]),
        'Escenario C (DIFERENTE)': np.array([0.30, 0.20, 0.15, 0.10]),
        'Escenario D (OPUESTO)': np.array([0.20, 0.40, 0.30, 0.00])
    }
    
    print("\nğŸ“Š SITUACIÃ“N ACTUAL DEL MERCADO:")
    print(f"   Vector: {situacion_actual}")
    print(f"   InterpretaciÃ³n:")
    print(f"     â€¢ Precio normalizado: {situacion_actual[0]:.2f} (ALTO)")
    print(f"     â€¢ RSI normalizado: {situacion_actual[1]:.2f} (MEDIO)")
    print(f"     â€¢ Sentimiento: {situacion_actual[2]:.2f} (POSITIVO)")
    print(f"     â€¢ Tendencia: {situacion_actual[3]:.2f} (ALCISTA)")
    
    print("\n" + "â”€"*90)
    print("COMPARANDO CON SITUACIONES HISTÃ“RICAS USANDO DIFERENTES MÃ‰TRICAS:")
    print("â”€"*90)
    
    # Tabla de comparaciÃ³n
    print(f"\n{'Escenario':<30} {'Manhattan':<12} {'Euclidean':<12} {'Minkowski':<12} {'Cosine Sim':<12} {'RecomendaciÃ³n'}")
    print("â”€"*90)
    
    for nombre, vector_historico in situaciones_historicas.items():
        # 1. Manhattan Distance
        manhattan = np.sum(np.abs(situacion_actual - vector_historico))
        
        # 2. Euclidean Distance
        euclidean = np.sqrt(np.sum((situacion_actual - vector_historico)**2))
        
        # 3. Minkowski Distance (p=3)
        minkowski = np.sum(np.abs(situacion_actual - vector_historico)**3)**(1/3)
        
        # 4. Cosine Similarity
        dot_product = np.dot(situacion_actual, vector_historico)
        norm_a = np.linalg.norm(situacion_actual)
        norm_b = np.linalg.norm(vector_historico)
        cosine_sim = dot_product / (norm_a * norm_b)
        
        # Determinar recomendaciÃ³n basada en el escenario histÃ³rico
        if 'SIMILAR' in nombre:
            recomendacion = "âœ… COMPRAR"
        elif 'DIFERENTE' in nombre or 'OPUESTO' in nombre:
            recomendacion = "âŒ VENDER"
        else:
            recomendacion = "â¡ï¸ MANTENER"
        
        print(f"{nombre:<30} {manhattan:>11.4f} {euclidean:>11.4f} {minkowski:>11.4f} {cosine_sim:>11.4f} {recomendacion}")
    
    # AnÃ¡lisis detallado
    print("\n" + "="*90)
    print("                           ANÃLISIS DE RESULTADOS")
    print("="*90)
    
    print("\nğŸ” Â¿QuÃ© observamos?")
    
    print("\n  1ï¸âƒ£ MANHATTAN DISTANCE (suma de diferencias absolutas):")
    print("     â€¢ Valores mÃ¡s bajos = mÃ¡s similar")
    print("     â€¢ Problema: Sensible a la escala de cada variable")
    print("     â€¢ En este caso: No distingue bien patrones similares")
    
    print("\n  2ï¸âƒ£ EUCLIDEAN DISTANCE (distancia en lÃ­nea recta):")
    print("     â€¢ Valores mÃ¡s bajos = mÃ¡s similar")
    print("     â€¢ Problema: Penaliza mucho diferencias en magnitud")
    print("     â€¢ En este caso: Mejor que Manhattan pero aÃºn limitado")
    
    print("\n  3ï¸âƒ£ MINKOWSKI DISTANCE (generalizaciÃ³n de las anteriores):")
    print("     â€¢ Valores mÃ¡s bajos = mÃ¡s similar")
    print("     â€¢ Problema: Hereda limitaciones de Manhattan/Euclidean")
    print("     â€¢ En este caso: No aporta ventajas significativas")
    
    print("\n  4ï¸âƒ£ COSINE SIMILARITY (Ã¡ngulo entre vectores) âœ…:")
    print("     â€¢ Valores cercanos a 1.0 = MUY similar")
    print("     â€¢ Valores cercanos a 0.0 = Ortogonales (sin relaciÃ³n)")
    print("     â€¢ Valores cercanos a -1.0 = Opuestos")
    print("     â€¢ Ventaja: SOLO mide la DIRECCIÃ“N del patrÃ³n, no la magnitud")
    print("     â€¢ En este caso: Identifica perfectamente situaciones similares")
    
    print("\nğŸ’¡ CONCLUSIÃ“N:")
    print("   Cosine Similarity = 0.9987 para 'Escenario A' indica que el patrÃ³n")
    print("   de mercado es CASI IDÃ‰NTICO a la situaciÃ³n actual, por lo tanto:")
    print("   â†’ Si en el pasado ESE patrÃ³n resultÃ³ en COMPRAR con Ã©xito,")
    print("   â†’ Entonces HOY tambiÃ©n deberÃ­amos COMPRAR")
    
    print("\nğŸ“ FÃ“RMULA APLICADA:")
    vector_a = situaciones_historicas['Escenario A (MUY SIMILAR)']
    dot = np.dot(situacion_actual, vector_a)
    norm_actual = np.linalg.norm(situacion_actual)
    norm_hist = np.linalg.norm(vector_a)
    
    print(f"\n   Actual:     {situacion_actual}")
    print(f"   HistÃ³rico:  {vector_a}")
    print(f"\n   Producto punto (AÂ·B):  {dot:.4f}")
    print(f"   Norma ||A||:           {norm_actual:.4f}")
    print(f"   Norma ||B||:           {norm_hist:.4f}")
    print(f"\n   Cosine Similarity = {dot:.4f} / ({norm_actual:.4f} Ã— {norm_hist:.4f})")
    print(f"                     = {dot:.4f} / {norm_actual * norm_hist:.4f}")
    print(f"                     = {dot / (norm_actual * norm_hist):.4f}")
    
    print("\n" + "="*90)
    print("FIN DE LA DEMOSTRACIÃ“N")
    print("="*90 + "\n")


# Para ejecutar la demostraciÃ³n, descomenta las siguientes lÃ­neas:
# print("\n\n")
# demostrar_cosine_similarity()
# print("\n\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO ADICIONAL: SISTEMA DE RECOMENDACIÃ“N POR SIMILITUD (COMENTADO)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NOTA: Este mÃ³dulo requiere NLTK y un archivo CSV adicional.
# Para activarlo:
#   1. Instalar: pip install nltk scikit-learn
#   2. Crear el archivo: analisis-empresas-peru.csv
#   3. Descomentar el cÃ³digo siguiente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
# ==============================
#   SISTEMA DE RECOMENDACIÃ“N
#   Datos: Noticias de empresas peruanas (CSV)
#   Funciones: Limpieza, tokenizaciÃ³n, TF-IDF,
#              recomendaciÃ³n por similitud
#              anÃ¡lisis de sentimiento
#              visualizaciÃ³n de resultados
# ==============================

# ---------- ImportaciÃ³n de librerÃ­as ----------
import pandas as pd
import nltk
import os
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Crear carpetas necesarias si no existen
os.makedirs("resultadocodigo", exist_ok=True)

# Descargar recursos NLTK la primera vez
nltk.download('punkt')
nltk.download('stopwords')

# ---------- Cargar datos ----------
df = pd.read_csv("analisis-empresas-peru.csv", encoding='latin1')

# Convertir texto a minÃºsculas
df['Texto'] = df['Texto'].str.lower()

# ---------- Limpieza general del texto ----------
stop_words = set(stopwords.words('spanish'))

def limpiar_texto(texto):
    \"\"\"
    Limpia el texto eliminando stopwords y puntuaciÃ³n.
    Devuelve el texto limpio.
    \"\"\"
    tokens = word_tokenize(texto)
    tokens_limpios = [word for word in tokens if word.isalpha() and word not in stop_words]
    return " ".join(tokens_limpios)

df['texto_limpio'] = df['Texto'].apply(limpiar_texto)

# ---------- VectorizaciÃ³n TF-IDF ----------
tfidf = TfidfVectorizer()
matriz_tfidf = tfidf.fit_transform(df['texto_limpio'])

# ---------- FunciÃ³n de recomendaciÃ³n ----------
def recomendar(texto_usuario, top_n=5):
    \"\"\"
    Recibe un texto ingresado por el usuario,
    calcula su similitud con todas las noticias del dataset
    y devuelve las mÃ¡s similares.
    \"\"\"
    texto_usuario_limpio = limpiar_texto(texto_usuario)
    vector_usuario = tfidf.transform([texto_usuario_limpio])
    similitudes = cosine_similarity(vector_usuario, matriz_tfidf).flatten()
    indices_top = similitudes.argsort()[-top_n:][::-1]

    return df.iloc[indices_top][['Empresa', 'Texto', 'Valor']]

# ---------- Ejemplo de uso del sistema ----------
entrada_usuario = input("Ingrese una descripciÃ³n o noticia para recomendar empresas: ")
resultado = recomendar(entrada_usuario)

print("\n=== EMPRESAS RECOMENDADAS ===")
print(resultado)

# Guardar resultados como CSV en resultadocodigo/
resultado.to_csv("resultadocodigo/resultados_recomendacion.csv", index=False)

# ---------- GrÃ¡fica del ranking de empresas ----------
conteo_empresas = df["Empresa"].value_counts().head(10)

plt.figure(figsize=(10, 6))
plt.bar(conteo_empresas.index, conteo_empresas.values)
plt.xlabel("Empresa")
plt.ylabel("Frecuencia en noticias")
plt.title("Top 10 Empresas mÃ¡s mencionadas en noticias")
plt.xticks(rotation=45)

# Guardar la grÃ¡fica
plt.savefig("resultadocodigo/ranking_empresas.png", bbox_inches='tight')

plt.show()

print("\nLa grÃ¡fica y los resultados han sido guardados en la carpeta 'resultadocodigo/'.")
"""
